{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txpNLsE10vNV"
      },
      "source": [
        "# 02-BOW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_5G-8B90vNX"
      },
      "source": [
        "Now that we master the preprocessing, let's make our first Bag Of Words (BOW)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAHLH7wU0vNY"
      },
      "source": [
        "We will reuse our dataset of Coldplay songs to make a BOW."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcQGyCB40vNY"
      },
      "source": [
        "As usual, the first step is to import some libraries. So import *nltk* as well as all the libraries you will need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9mjMDegs0vNZ"
      },
      "outputs": [],
      "source": [
        "# Import NLTK and all the needed libraries\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVfRqjDZ0vNa"
      },
      "source": [
        "Load now the dataset in *coldplay.csv* using pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpKdl4_A0vNa",
        "outputId": "593ac980-18a5-4077-b802-509abf06e807"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Artist                           Song  \\\n",
            "0  Coldplay                 Another's Arms   \n",
            "1  Coldplay                Bigger Stronger   \n",
            "2  Coldplay                       Daylight   \n",
            "3  Coldplay                       Everglow   \n",
            "4  Coldplay  Every Teardrop Is A Waterfall   \n",
            "\n",
            "                                                Link  \\\n",
            "0            /c/coldplay/anothers+arms_21079526.html   \n",
            "1          /c/coldplay/bigger+stronger_20032648.html   \n",
            "2                 /c/coldplay/daylight_20032625.html   \n",
            "3                 /c/coldplay/everglow_21104546.html   \n",
            "4  /c/coldplay/every+teardrop+is+a+waterfall_2091...   \n",
            "\n",
            "                                              Lyrics  \n",
            "0  Late night watching tv  \\nUsed to be you here ...  \n",
            "1  I want to be bigger stronger drive a faster ca...  \n",
            "2  To my surprise, and my delight  \\nI saw sunris...  \n",
            "3  Oh, they say people come  \\nThey say people go...  \n",
            "4  I turn the music up, I got my records on  \\nI ...  \n"
          ]
        }
      ],
      "source": [
        "# TODO: Load the dataset in coldplay.csv\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('coldplay.csv')\n",
        "\n",
        "print(df.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNLkG3r-0vNb"
      },
      "source": [
        "You already know this dataset, but you can check it again if you want to refresh your memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHY0x0FO0vNc",
        "outputId": "f293e227-9093-4efa-ff47-e44451dacf23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 120 entries, 0 to 119\n",
            "Data columns (total 4 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Artist  120 non-null    object\n",
            " 1   Song    120 non-null    object\n",
            " 2   Link    120 non-null    object\n",
            " 3   Lyrics  120 non-null    object\n",
            "dtypes: object(4)\n",
            "memory usage: 3.9+ KB\n"
          ]
        }
      ],
      "source": [
        "# TODO: Explore the data\n",
        "df.info()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIfRIpiu0vNc"
      },
      "source": [
        "Now using the *CountVectorizer* of scikit-learn, make a BOW of all the lyrics of Coldplay, and print the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mbv4Am50vNc",
        "outputId": "816e719a-fd2d-4615-abc0-048310e24246"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 20)\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute a BOW\n",
        "vectorizer = CountVectorizer(stop_words='english', analyzer='word')\n",
        "bow = vectorizer.fit_transform(df['Lyrics']).toarray()\n",
        "print(bow.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmqZz-gA0vNc"
      },
      "source": [
        "Now that we have the BOW matrix, we would like to have a new dataframe having the BOW for each song, and as columns the corresponding words (just as we did in the lecture at the end).\n",
        "\n",
        "So that at the end we would end up with a dataframe containing something like the following (120 raws for 120 songs, and as many columns as words):\n",
        "\n",
        "| | ah | adventure | ... | yeah\n",
        "|---|---|---|---|---|\n",
        "| 0 | 0 | 1 | ... | 4 |\n",
        "| 1 | 8 | 0 | ... | 2 |\n",
        "|...|...|...|...|...|\n",
        "| 119 | 5 | 0 | ... | 8 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwasEPrC0vNd",
        "outputId": "0638cc9e-b04e-4099-cf4b-66da7dbee6ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   best  don  gave  look  morning  need  rise  rule  seas  shine  sleep  \\\n",
            "0     0    0     0     2        0     0     0     0     0      1      0   \n",
            "1     0    0     1     0        1     0     1     1     1      0      1   \n",
            "2     1    1     0     0        0     1     0     0     0      0      0   \n",
            "\n",
            "   stars  succeed  try  used  want  word  world  yeah  yellow  \n",
            "0      1        0    0     0     0     0      0     1       1  \n",
            "1      0        0    0     1     0     1      1     0       0  \n",
            "2      0        1    1     0     1     0      0     0       0  \n"
          ]
        }
      ],
      "source": [
        "# TODO: Create a new dataframe containing the BOW outputs and the corresponding words as columns. And print it\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(stop_words='english', analyzer='word')\n",
        "\n",
        "bow = vectorizer.fit_transform(df['Lyrics']).toarray()\n",
        "\n",
        "words = vectorizer.get_feature_names_out()\n",
        "\n",
        "bow_df = pd.DataFrame(bow, columns=words)\n",
        "\n",
        "# Print the new DataFrame\n",
        "print(bow_df)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-_oKV3D0vNd"
      },
      "source": [
        "Well as you see we're still having some issue, we have some tokens that are not words, like '10' or '2000'.\n",
        "\n",
        "To get rid of that, we could use directly regular expressions within the function. Another solution would be to make preprocessing before using the function *CountVectorizer*.\n",
        "\n",
        "For the moment, we won't pay attention to this issue. But if you are curious and have time, you can find on google how to remove those words using the *CountVectorizer*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEqUF4hm0vNd"
      },
      "source": [
        "Now we would like to see what are the most used words by Coldplay."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "4m1M76cF0vNd",
        "outputId": "e8cf9046-5874-4bb5-8b6e-331f3529031e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'look'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "sum_bow = bow_df.sum()\n",
        "sum_bow.idxmax()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhIC_qH70vNd"
      },
      "source": [
        "So what is the most used word? Are you surprised?\n",
        "\n",
        "Now make a sort in order to show the 10 most used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tf2zFEKd0vNe",
        "outputId": "eb390980-49b3-4d81-b907-357e6ff3370f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "look       2\n",
              "best       1\n",
              "stars      1\n",
              "yeah       1\n",
              "world      1\n",
              "word       1\n",
              "want       1\n",
              "used       1\n",
              "try        1\n",
              "succeed    1\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# TODO: print the 10 most used word by Coldplay\n",
        "sum_bow.sort_values(ascending=False)[:10]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1X4_QmM0vNe"
      },
      "source": [
        "Here it is! You know the Coldplay lyrics more than the singers now!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}